{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning notes\n",
    "# 1. Chromedriver is located in \"C:\\Windows\". When you need to update the driver, replace the .exe file in there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.subplots as sp\n",
    "import plotly.graph_objects as go\n",
    "import re\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import os\n",
    "import glob\n",
    "pause_time = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to dissect the user_activity string\n",
    "def dissect_user_activity(activity):\n",
    "    # Initialize default values\n",
    "    is_local_guide = False\n",
    "    n_user_reviews = 0\n",
    "    n_user_photos = 0\n",
    "\n",
    "    # Check for 'Local Guide'\n",
    "    if 'Local Guide' in activity:\n",
    "        is_local_guide = True\n",
    "\n",
    "    # Extract the number of reviews\n",
    "    reviews_match = re.search(r'(\\d+)\\s+reviews?', activity)\n",
    "    if reviews_match:\n",
    "        n_user_reviews = int(reviews_match.group(1))\n",
    "\n",
    "    # Extract the number of photos\n",
    "    photos_match = re.search(r'(\\d+)\\s+photos?', activity)\n",
    "    if photos_match:\n",
    "        n_user_photos = int(photos_match.group(1))\n",
    "\n",
    "    return pd.Series([is_local_guide, n_user_reviews, n_user_photos])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estepalace: 'https://www.google.com/maps/place/estepalace+Hair+Transplant+Center/@41.0681014,28.9914843,17z/data=!3m1!4b1!4m6!3m5!1s0x14cab820372c2ef3:0x711c752f40eda6ca!8m2!3d41.0681014!4d28.993673!16s%2Fg%2F1tjj8mtd'\n",
    "# estetistanbul: 'https://www.google.com/maps/place/Estet+Istanbul+Saglik+%26+Estetik/@41.0838758,29.011377,17z/data=!3m1!4b1!4m6!3m5!1s0x14cab66f08308d5b:0x87a8dbfee5c3f4b8!8m2!3d41.0838758!4d29.0135657!16s%2Fg%2F1tctn_f4'\n",
    "# regina: 'https://www.google.com/maps/place/Regina+Med+Clinic+-+Sa%C3%A7+Ekimi+(Hair+Transplantation)+ve+Medikal+Estetik/@41.0557593,28.9961466,17z/data=!3m1!4b1!4m6!3m5!1s0x14cab71b379cabfd:0x33b9891e51c1350a!8m2!3d41.0557593!4d28.9987215!16s%2Fg%2F11t320c01n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()  # Optional argument, if not specified will search path.\n",
    "driver.implicitly_wait(pause_time)\n",
    "\n",
    "df_name = \"estepalace\"\n",
    "url = 'https://www.google.com/maps/place/estepalace+Hair+Transplant+Center/@41.0681014,28.9914843,17z/data=!3m1!4b1!4m6!3m5!1s0x14cab820372c2ef3:0x711c752f40eda6ca!8m2!3d41.0681014!4d28.993673!16s%2Fg%2F1tjj8mtd'\n",
    "driver.get(url)\n",
    "time.sleep(pause_time)\n",
    "\n",
    "# Accept the cookies (ctrl q)\n",
    "driver.find_element(By.XPATH, '//*[@id=\"yDmH0d\"]/c-wiz/div/div/div/div[2]/div[1]/div[3]/div[1]/div[1]/form[2]/div/div/button/span').click()\n",
    "time.sleep(pause_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n"
     ]
    }
   ],
   "source": [
    "#Find the total number of ratings\n",
    "total_number_of_ratings = driver.find_element(By.XPATH, '//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div[1]/div[1]/div[2]/div/div[1]/div[2]/span[2]/span[1]/span').text.split(\" \")[0]\n",
    "total_number_of_ratings = total_number_of_ratings.replace(\"(\",\"\")\n",
    "total_number_of_ratings = int(total_number_of_ratings.replace(\")\",\"\"))\n",
    "print(total_number_of_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on reviews and lay them out\n",
    "xpath_str = '//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div/div/button[2]/div[2]/div[2]'\n",
    "driver.find_element(By.XPATH, xpath_str).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "157\n"
     ]
    }
   ],
   "source": [
    "# # Alternative way to scroll down the review window\n",
    "# html = driver.find_element(By.XPATH, '//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]')\n",
    "# html.send_keys(Keys.END)\n",
    "\n",
    "# Get scroll height\n",
    "# last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "n_loaded_objects = int(len(driver.find_elements(By.CLASS_NAME, 'jftiEf')))\n",
    "ele = driver.find_element(By.XPATH, '//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]')\n",
    "\n",
    "# Scroll the page down to the bottom until there are no more reviews to load\n",
    "while n_loaded_objects < int(total_number_of_ratings)-1:\n",
    "    driver.execute_script('arguments[0].scrollBy(0, 5000);', ele)\n",
    "    time.sleep(pause_time)\n",
    "    n_loaded_objects = int(len(driver.find_elements(By.CLASS_NAME, 'jftiEf')))\n",
    "    print(n_loaded_objects)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "elems = driver.find_elements(By.CLASS_NAME, 'kyuRq.fontTitleSmall.WOKzJe') \n",
    "# By clicking on the \"See original\" buttons, each review is reverted back to its original language\n",
    "for elem in elems:\n",
    "        if 'See original' in elem.text:\n",
    "                try:\n",
    "                    elem.click()\n",
    "                except:\n",
    "                       continue\n",
    "# <button class=\"kyuRq fontTitleSmall WOKzJe\" role=\"switch\" aria-checked=\"true\" aria-controls=\"ChZDSUhNMG9nS0VJQ0FnSURRcVpUdkVBEAE\" data-review-id=\"ChZDSUhNMG9nS0VJQ0FnSURRcVpUdkVBEAE\" jsaction=\"pane.review.showReviewInOriginal\" jslog=\"170842; track:click; mutable:true;metadata:WyIwYWhVS0V3aXhxZF9PNWE2QkF4WFdpdjBISGN5ekFzWVE0UjRJTVNnSiJd\"> <span><span class=\"fontBodySmall iUHfzf\">Translated by Google</span> <span class=\"fontBodySmall iUHfzf\">ãƒ»</span></span> <span>See original (Turkish)</span></button>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "elems = driver.find_elements(By.CLASS_NAME, 'w8nwRe.kyuRq') \n",
    "# By clicking on the \"More\" buttons, each review that is too long to be fully displayed, is extended to its full format.\n",
    "for elem in elems:\n",
    "        if elem.text == \"More\":\n",
    "                try:\n",
    "                    elem.click()\n",
    "                except:\n",
    "                       continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all review elements just once\n",
    "review_elements = driver.find_elements(By.CLASS_NAME, 'jftiEf')\n",
    "\n",
    "# Initialize lists to store review data\n",
    "reviews_data = []\n",
    "\n",
    "# Loop through each review element to extract information\n",
    "for review_element in review_elements:\n",
    "    review_data = {}\n",
    "    \n",
    "    # Extract user ID and rating ID\n",
    "    user_info_element = review_element.find_element(By.CLASS_NAME, 'WEBjve')\n",
    "    review_data['user_id'] = user_info_element.get_attribute('data-href')\n",
    "    review_data['rating_id'] = user_info_element.get_attribute('data-review-id')\n",
    "    \n",
    "    # Extract rating date and star rating\n",
    "    rating_date_element = review_element.find_element(By.CLASS_NAME, 'rsqaWe')\n",
    "    review_data['rating_date'] = rating_date_element.text\n",
    "    \n",
    "    star_rating_element = review_element.find_element(By.CLASS_NAME, 'kvMYJc')\n",
    "    review_data['star_rating'] = star_rating_element.get_attribute('aria-label')\n",
    "    \n",
    "    # Attempt to extract review text and review language\n",
    "    try:\n",
    "        review_text_element = review_element.find_element(By.CLASS_NAME, 'MyEned')\n",
    "        review_data['review'] = review_text_element.text\n",
    "        review_data['review_lang'] = review_text_element.get_attribute('lang')\n",
    "    except:\n",
    "        review_data['review'] = ''\n",
    "        review_data['review_lang'] = ''\n",
    "    \n",
    "    # Attempt to extract the user activity data if present\n",
    "    try:\n",
    "        user_activity_element = review_element.find_elements(By.CLASS_NAME, 'RfnDt')\n",
    "        user_activity_element = user_activity_element[0]  # Assuming first element is the user activity data\n",
    "        review_data['user_activity'] = user_activity_element.text\n",
    "    except:\n",
    "        review_data['user_activity'] = ''\n",
    "    \n",
    "    # Attempt to extract response details if present\n",
    "    try:\n",
    "        response_elements = review_element.find_elements(By.CLASS_NAME, 'DZSIDd')\n",
    "        response_date_element = response_elements[0]  # Assuming first element is the response date\n",
    "        review_data['response_date'] = response_date_element.text if response_date_element else ''\n",
    "        \n",
    "        response_text_elements = review_element.find_elements(By.CLASS_NAME, 'wiI7pd')\n",
    "        response_text_element = response_text_elements[-1]  # Assuming the last element is the response text\n",
    "        review_data['response'] = response_text_element.text if response_text_element else ''\n",
    "        review_data['response_lang'] = response_text_element.get_attribute('lang') if response_text_element else ''\n",
    "    except:\n",
    "        review_data['response_date'] = ''\n",
    "        review_data['response'] = ''\n",
    "        review_data['response_lang'] = ''\n",
    "    \n",
    "    # Add the collected data to the list\n",
    "    reviews_data.append(review_data)\n",
    "\n",
    "# # Example: Print out the collected review data\n",
    "# for data in reviews_data:\n",
    "#     print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(reviews_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_date_tf = []\n",
    "\n",
    "# Get today's date\n",
    "today = datetime.date.today()\n",
    "\n",
    "\n",
    "for raw_rating in df.rating_date:\n",
    "    units = int(1 if raw_rating.split(' ')[0] == 'a' else raw_rating.split(' ')[0])\n",
    "\n",
    "    if 'year' in raw_rating:\n",
    "        factor = 365\n",
    "    elif 'month' in raw_rating:\n",
    "        factor = 30\n",
    "    elif 'week' in raw_rating:\n",
    "        factor = 7\n",
    "    elif 'day' in raw_rating:\n",
    "        factor = 1\n",
    "    \n",
    "    approx_days = factor*units\n",
    "    approx_date = today - datetime.timedelta(days=approx_days)\n",
    "    rating_date_tf.append(approx_date)\n",
    "\n",
    "df['rating_date_approx'] = rating_date_tf\n",
    "df['rating_date_approx'] = pd.to_datetime(df['rating_date_approx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_date_tf = []\n",
    "\n",
    "# Get today's date\n",
    "today = datetime.date.today()\n",
    "\n",
    "\n",
    "for raw_rating in df.response_date:\n",
    "    try:\n",
    "        units = int(1 if raw_rating.split(' ')[0] == 'a' else raw_rating.split(' ')[0])\n",
    "\n",
    "        if 'year' in raw_rating:\n",
    "            factor = 365\n",
    "        elif 'month' in raw_rating:\n",
    "            factor = 30\n",
    "        elif 'week' in raw_rating:\n",
    "            factor = 7\n",
    "        elif 'day' in raw_rating:\n",
    "            factor = 1\n",
    "        \n",
    "        approx_days = factor*units\n",
    "        approx_date = today - datetime.timedelta(days=approx_days)\n",
    "        response_date_tf.append(approx_date)\n",
    "    except:\n",
    "        response_date_tf.append('')\n",
    "\n",
    "df['response_date_approx'] = response_date_tf\n",
    "df['response_date_approx'] = pd.to_datetime(df['response_date_approx'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['star_rating'] = [int(x[:1]) for x in df['star_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = [x.replace('\\n', ' ') for x in df['review']]\n",
    "df['response'] = [x.replace('\\n', ' ') for x in df['response']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to create new columns\n",
    "df[['is_local_guide', 'n_user_reviews', 'n_user_photos']] = df['user_activity'].apply(dissect_user_activity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle('regina.pkl'.format(df_name))\n",
    "df.to_pickle('{}.pkl'.format(df_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle('estetistanbul.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a0d4cdeee540f8984e13be77101360552ef09a3a598bd8752846f77c2e4d1d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
